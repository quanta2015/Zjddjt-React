{"ast":null,"code":"'use strict';\n\nvar TransformStream = require('stream').Transform,\n    DevNullStream = require('./dev_null_stream'),\n    inherits = require('util').inherits,\n    Tokenizer = require('../tokenizer'),\n    LocationInfoTokenizerMixin = require('../extensions/location_info/tokenizer_mixin'),\n    ParserFeedbackSimulator = require('./parser_feedback_simulator'),\n    mergeOptions = require('../utils/merge_options');\n\nvar DEFAULT_OPTIONS = {\n  locationInfo: false\n};\n\nvar SAXParser = module.exports = function (options) {\n  TransformStream.call(this);\n  this.options = mergeOptions(DEFAULT_OPTIONS, options);\n  this.tokenizer = new Tokenizer(options);\n  if (this.options.locationInfo) new LocationInfoTokenizerMixin(this.tokenizer);\n  this.parserFeedbackSimulator = new ParserFeedbackSimulator(this.tokenizer);\n  this.pendingText = null;\n  this.currentTokenLocation = void 0;\n  this.lastChunkWritten = false;\n  this.stopped = false; // NOTE: always pipe stream to the /dev/null stream to avoid\n  // `highWaterMark` hit even if we don't have consumers.\n  // (see: https://github.com/inikulin/parse5/issues/97#issuecomment-171940774)\n\n  this.pipe(new DevNullStream());\n};\n\ninherits(SAXParser, TransformStream); //TransformStream implementation\n\nSAXParser.prototype._transform = function (chunk, encoding, callback) {\n  if (!this.stopped) {\n    this.tokenizer.write(chunk.toString('utf8'), this.lastChunkWritten);\n\n    this._runParsingLoop();\n  }\n\n  this.push(chunk);\n  callback();\n};\n\nSAXParser.prototype._flush = function (callback) {\n  callback();\n};\n\nSAXParser.prototype.end = function (chunk, encoding, callback) {\n  this.lastChunkWritten = true;\n  TransformStream.prototype.end.call(this, chunk, encoding, callback);\n};\n\nSAXParser.prototype.stop = function () {\n  this.stopped = true;\n}; //Internals\n\n\nSAXParser.prototype._runParsingLoop = function () {\n  do {\n    var token = this.parserFeedbackSimulator.getNextToken();\n    if (token.type === Tokenizer.HIBERNATION_TOKEN) break;\n\n    if (token.type === Tokenizer.CHARACTER_TOKEN || token.type === Tokenizer.WHITESPACE_CHARACTER_TOKEN || token.type === Tokenizer.NULL_CHARACTER_TOKEN) {\n      if (this.options.locationInfo) {\n        if (this.pendingText === null) this.currentTokenLocation = token.location;else this.currentTokenLocation.endOffset = token.location.endOffset;\n      }\n\n      this.pendingText = (this.pendingText || '') + token.chars;\n    } else {\n      this._emitPendingText();\n\n      this._handleToken(token);\n    }\n  } while (!this.stopped && token.type !== Tokenizer.EOF_TOKEN);\n};\n\nSAXParser.prototype._handleToken = function (token) {\n  if (this.options.locationInfo) this.currentTokenLocation = token.location;\n  if (token.type === Tokenizer.START_TAG_TOKEN) this.emit('startTag', token.tagName, token.attrs, token.selfClosing, this.currentTokenLocation);else if (token.type === Tokenizer.END_TAG_TOKEN) this.emit('endTag', token.tagName, this.currentTokenLocation);else if (token.type === Tokenizer.COMMENT_TOKEN) this.emit('comment', token.data, this.currentTokenLocation);else if (token.type === Tokenizer.DOCTYPE_TOKEN) this.emit('doctype', token.name, token.publicId, token.systemId, this.currentTokenLocation);\n};\n\nSAXParser.prototype._emitPendingText = function () {\n  if (this.pendingText !== null) {\n    this.emit('text', this.pendingText, this.currentTokenLocation);\n    this.pendingText = null;\n  }\n};","map":null,"metadata":{},"sourceType":"script"}